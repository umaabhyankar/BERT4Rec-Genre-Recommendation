{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Install required packages\n",
        "!pip install numpy torch tqdm wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lLK8VqEq_5-",
        "outputId": "93ad0040-ca02-4cb2-d64f-5a9dd5cf6452"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Clone the repository\n",
        "!git clone https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch.git\n",
        "%cd BERT4Rec-VAE-Pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gommmGWrBr4",
        "outputId": "37a373b2-b94e-4462-fb59-f06de9fe7875"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BERT4Rec-VAE-Pytorch' already exists and is not an empty directory.\n",
            "/content/BERT4Rec-VAE-Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 3. Download MovieLens-1M dataset\n",
        "# !wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "# !unzip ml-1m.zip -d datasets/\n",
        "\n",
        "\n",
        "import os\n",
        "os.makedirs('Data/ml-1m', exist_ok=True)\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip -d Data/\n",
        "\n",
        "# Verify the files are there\n",
        "!ls Data/ml-1m/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2UjXoTqrizw",
        "outputId": "c489cb78-4820-4b51-f6a8-617045e64054"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-25 09:40:42--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‚Äòml-1m.zip.24‚Äô\n",
            "\n",
            "ml-1m.zip.24        100%[===================>]   5.64M  11.0MB/s    in 0.5s    \n",
            "\n",
            "2025-06-25 09:40:42 (11.0 MB/s) - ‚Äòml-1m.zip.24‚Äô saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "replace Data/ml-1m/movies.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Data/ml-1m/movies.dat   \n",
            "replace Data/ml-1m/ratings.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Data/ml-1m/ratings.dat  \n",
            "replace Data/ml-1m/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Data/ml-1m/README       \n",
            "replace Data/ml-1m/users.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Data/ml-1m/users.dat    \n",
            "movies.dat  ratings.dat  README  users.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Verify GPU availability\n",
        "import torch\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut657bkJr9Do",
        "outputId": "98fb6de0-9aee-4bf9-f7b0-a9e69cbdbd38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Device Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create necessary directories\n",
        "import os\n",
        "os.makedirs('models/bert_genre', exist_ok=True)\n",
        "os.makedirs('trainers', exist_ok=True)\n",
        "os.makedirs('dataloaders', exist_ok=True)\n",
        "os.makedirs('datasets', exist_ok=True)"
      ],
      "metadata": {
        "id": "MBIT87iosCPz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update BERT genre model\n",
        "%%writefile models/bert_genre.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from .bert import BERT\n",
        "\n",
        "class BERTGenreModel(nn.Module):\n",
        "    @classmethod\n",
        "    def code(cls):\n",
        "        return 'bert_genre'\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.bert = BERT(args)\n",
        "        self.num_items = args.num_items\n",
        "        self.genre_embedding_size = args.genre_embedding_size\n",
        "        self.num_genres = args.num_genres\n",
        "\n",
        "        # Genre embeddings\n",
        "        self.genre_embeddings = nn.Embedding(self.num_genres, self.genre_embedding_size)\n",
        "\n",
        "        # Output layer for genre-item predictions\n",
        "        self.output_layer = nn.Linear(args.bert_hidden_units + self.genre_embedding_size, self.num_items)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"Initialize weights for BERT and output layer\"\"\"\n",
        "        self.bert.init_weights()\n",
        "        nn.init.xavier_normal_(self.output_layer.weight)\n",
        "        nn.init.zeros_(self.output_layer.bias)\n",
        "\n",
        "    def forward(self, x, genre_matrix):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # BERT output: [batch_size, seq_len, hidden_dim]\n",
        "        bert_output = self.bert(x)\n",
        "\n",
        "        # Get final token embedding (CLS token)\n",
        "        bert_output = bert_output[:, -1, :]  # [batch_size, hidden_dim]\n",
        "\n",
        "        # Repeat genre embeddings: [batch_size, num_genres, genre_emb_dim]\n",
        "        genre_embeddings = self.genre_embeddings.weight  # [num_genres, genre_emb_dim]\n",
        "        genre_embeddings_expanded = genre_embeddings.unsqueeze(0).expand(batch_size, -1, -1)\n",
        "\n",
        "        # Expand BERT output to match genre dimension: [batch_size, num_genres, hidden_dim]\n",
        "        bert_output_expanded = bert_output.unsqueeze(1).expand(-1, self.num_genres, -1)\n",
        "\n",
        "        # Concatenate: [batch_size, num_genres, hidden + genre_emb_dim]\n",
        "        combined = torch.cat([bert_output_expanded, genre_embeddings_expanded], dim=-1)\n",
        "\n",
        "        # Final output layer: [batch_size, num_genres, num_items]\n",
        "        logits = self.output_layer(combined)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "    def get_topk_per_genre(self, x, genre_matrix, k=5):\n",
        "        \"\"\"Get top-k items for each genre\"\"\"\n",
        "        logits = self.forward(x, genre_matrix)\n",
        "        topk_per_genre = torch.topk(logits, k, dim=2).indices  # Shape: [batch_size, num_genres, k]\n",
        "        return topk_per_genre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0rf4kcNsKMf",
        "outputId": "d782e347-8d17-4d5f-e389-4199e269b24b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/bert_genre.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Write BERT genre trainer\n",
        "%%writefile trainers/bert_genre_trainer.py\n",
        "from .base import AbstractTrainer as BaseTrainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTGenreTrainer(BaseTrainer):\n",
        "    @classmethod\n",
        "    def code(cls):\n",
        "        return 'bert_genre'\n",
        "\n",
        "    def __init__(self, args, model, train_dataloader, val_dataloader, test_dataloader, export_root):\n",
        "        super().__init__(args, model, train_dataloader, val_dataloader, test_dataloader, export_root)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def add_extra_loggers(self):\n",
        "        pass\n",
        "\n",
        "    def log_extra_train_info(self, log_data):\n",
        "        pass\n",
        "\n",
        "    def log_extra_val_info(self, log_data):\n",
        "        pass\n",
        "\n",
        "    def calculate_loss(self, batch):\n",
        "        \"\"\"\n",
        "        batch = (seqs, labels, genre_matrix)\n",
        "        logits: [batch_size, num_genres, num_items]\n",
        "        labels: [batch_size, num_genres]\n",
        "        \"\"\"\n",
        "        seqs, labels, genre_matrix = batch\n",
        "        logits = self.model(seqs, genre_matrix)  # shape: [B, G, I]\n",
        "\n",
        "        batch_size, num_genres, num_items = logits.shape\n",
        "        logits = logits.view(-1, num_items)           # [B * G, I]\n",
        "        labels = labels.view(-1)                      # [B * G]\n",
        "\n",
        "        loss = self.criterion(logits, labels)         # CrossEntropyLoss across all genre-item targets\n",
        "        return loss\n",
        "\n",
        "    def calculate_metrics(self, batch):\n",
        "        \"\"\"\n",
        "        Calculate Recall@5 per genre, averaged over all users\n",
        "        \"\"\"\n",
        "        seqs, labels, genre_matrix = batch\n",
        "        logits = self.model(seqs, genre_matrix)  # [B, G, I]\n",
        "\n",
        "        # Top-5 item indices per genre\n",
        "        top5 = torch.topk(logits, 5, dim=2).indices  # Expecting: [B, G, 5]\n",
        "\n",
        "        # Add these debug prints\n",
        "        print(\"top5 shape:\", top5.shape)        # Should be [B, G, 5]\n",
        "        print(\"labels shape:\", labels.shape)    # Should be [B]\n",
        "\n",
        "        # Ensure proper shape alignment: [B, G, 1]\n",
        "        labels_expanded = labels.unsqueeze(1).expand(-1, top5.size(1)).unsqueeze(2)\n",
        "        print(\"labels_expanded shape:\", labels_expanded.shape)  # Should be [B, G, 1]\n",
        "\n",
        "        # Check if label is in top-5 per genre\n",
        "        hits = (top5 == labels_expanded).any(dim=2).float()  # [B, G]\n",
        "\n",
        "        recall_5 = hits.mean().item()  # scalar average over all users and genres\n",
        "\n",
        "        return {\n",
        "            \"Recall@5\": recall_5\n",
        "        }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2A0rj_bsM6O",
        "outputId": "c5416f8d-83ac-4ad7-ee06-1f64b757b82e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting trainers/bert_genre_trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update BERT genre dataloader\n",
        "%%writefile dataloaders/bert_genre.py\n",
        "from .base import AbstractDataloader\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BERTGenreDataloader(AbstractDataloader):\n",
        "    @classmethod\n",
        "    def code(cls):\n",
        "        return 'bert_genre'\n",
        "\n",
        "    def __init__(self, args, dataset):\n",
        "        super().__init__(args, dataset)\n",
        "        self.dataset = dataset\n",
        "        self.max_len = args.bert_max_len\n",
        "        self.mask_prob = args.bert_mask_prob\n",
        "        self.CLOZE_MASK_TOKEN = self.dataset.get_num_items() + 1\n",
        "\n",
        "    def _get_dataloader(self, data, shuffle):\n",
        "        # Pre-allocate numpy arrays\n",
        "        n_samples = len(data)\n",
        "        sequences = np.zeros((n_samples, self.max_len), dtype=np.int32)\n",
        "        labels = np.zeros(n_samples, dtype=np.int32)\n",
        "        genre_matrices = []\n",
        "\n",
        "        idx = 0\n",
        "        for user_id, items in data.items():\n",
        "            # Add items to sequence\n",
        "            seq = np.zeros([self.max_len], dtype=np.int32)\n",
        "            seq_idx = self.max_len - 1\n",
        "\n",
        "            for i in reversed(items[:-1]):\n",
        "                seq[seq_idx] = i\n",
        "                seq_idx -= 1\n",
        "                if seq_idx == -1: break\n",
        "\n",
        "            sequences[idx] = seq\n",
        "\n",
        "            # Get positive item and its genre matrix\n",
        "            pos_id = items[-1]\n",
        "            genre_matrix = self.dataset.get_genre_matrix([pos_id])\n",
        "            genre_matrices.append(genre_matrix.numpy())\n",
        "\n",
        "            labels[idx] = pos_id\n",
        "            idx += 1\n",
        "\n",
        "        # Convert to tensors\n",
        "        sequences = torch.LongTensor(sequences)\n",
        "        labels = torch.LongTensor(labels)\n",
        "        genre_matrices = torch.FloatTensor(np.stack(genre_matrices))\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(sequences, labels, genre_matrices)\n",
        "\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.args.train_batch_size,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=self.args.workers\n",
        "        )\n",
        "\n",
        "    def get_pytorch_dataloaders(self):\n",
        "        train = self._get_dataloader(self.dataset.train, shuffle=True)\n",
        "        val = self._get_dataloader(self.dataset.val, shuffle=False)\n",
        "        test = self._get_dataloader(self.dataset.test, shuffle=False)\n",
        "        return train, val, test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNM-G2h0sWdB",
        "outputId": "7f58479e-5ee4-451f-ad78-e6d557c33b32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataloaders/bert_genre.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update templates.py\n",
        "%%writefile templates.py\n",
        "# Update templates.py\n",
        "import argparse\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "\n",
        "def train_bert_genre():\n",
        "    \"\"\"Train the BERT genre model with genre-specific metrics\"\"\"\n",
        "    parser = argparse.ArgumentParser(description='RecPlay')\n",
        "    args = parser.parse_args([])\n",
        "\n",
        "    # Experiment settings\n",
        "    args.experiment_dir = os.path.join(os.getcwd(), 'experiments')\n",
        "    args.experiment_description = 'genre_recommendation'\n",
        "\n",
        "    # Model and dataset settings\n",
        "    args.model_code = 'bert_genre'\n",
        "    args.dataset_code = 'ml-1m'\n",
        "    args.min_rating = 0 if args.dataset_code == 'ml-1m' else 4\n",
        "    args.min_uc = 5\n",
        "    args.min_sc = 0\n",
        "    args.split = 'leave_one_out'\n",
        "\n",
        "    # Model initialization\n",
        "    args.model_init_seed = 0\n",
        "\n",
        "    # Dataloader settings\n",
        "    args.dataloader_code = 'bert_genre'\n",
        "    args.train_negative_sampler_code = 'random'\n",
        "    args.train_negative_sample_size = 0\n",
        "    args.train_batch_size = 64\n",
        "    args.val_batch_size = 64\n",
        "    args.test_batch_size = 64\n",
        "    args.train_negative_sampling_seed = 0\n",
        "    args.test_negative_sampling_seed = 98765\n",
        "    args.dataloader_random_seed = 98765\n",
        "    args.workers = 0\n",
        "\n",
        "    # Trainer settings\n",
        "    args.trainer_code = 'bert_genre'\n",
        "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    args.num_gpu = 1 if torch.cuda.is_available() else 0\n",
        "    args.device_idx = 0\n",
        "    args.optimizer = 'Adam'\n",
        "    args.lr = 0.001\n",
        "    args.num_epochs = 100   ###############################################################################  NUMBER OF EPOCHS ##################################\n",
        "    args.metric_ks = [1, 5, 10]\n",
        "    args.best_metric = 'NDCG@10'\n",
        "    args.l2_reg = 0.0\n",
        "    args.weight_decay = 0.0\n",
        "    args.momentum = 0.9\n",
        "\n",
        "    # Learning rate schedule\n",
        "    args.enable_lr_schedule = True\n",
        "    args.decay_step = 20\n",
        "    args.gamma = 0.1\n",
        "\n",
        "    # Logging settings\n",
        "    args.log_period_as_iter = 100  # Log every 100 iterations\n",
        "    args.log_period_as_epoch = 1   # Log every epoch\n",
        "\n",
        "    # BERT genre-specific parameters\n",
        "    args.bert_max_len = 100\n",
        "    args.bert_num_blocks = 2\n",
        "    args.bert_num_heads = 4\n",
        "    args.bert_hidden_units = 256\n",
        "    args.bert_dropout = 0.1\n",
        "    args.bert_mask_prob = 0.15\n",
        "    args.genre_embedding_size = 64\n",
        "    args.num_items = 3706\n",
        "    args.num_genres = 18\n",
        "\n",
        "    return args\n",
        "\n",
        "def set_template(args):\n",
        "    if args.template == 'train_bert_genre':\n",
        "        args = train_bert_genre()\n",
        "    return args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxs5TWvJsaGj",
        "outputId": "d9feb0b2-ed34-47c3-9352-7b910556b4fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting templates.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update options.py\n",
        "%%writefile options.py\n",
        "import sys\n",
        "import argparse\n",
        "import torch\n",
        "from templates import set_template\n",
        "\n",
        "# Check if running in Colab\n",
        "is_colab = 'ipykernel' in sys.argv[0]\n",
        "\n",
        "# Create argument parser\n",
        "parser = argparse.ArgumentParser(description='RecPlay')\n",
        "\n",
        "# Add all arguments\n",
        "parser.add_argument('--dataset_code', type=str, default='ml-1m', choices=['ml-1m', 'ml-20m'])\n",
        "parser.add_argument('--min_rating', type=int, default=0, help='Minimum rating to include')\n",
        "parser.add_argument('--min_uc', type=int, default=5, help='Filter threshold for users')\n",
        "parser.add_argument('--min_sc', type=int, default=0, help='Filter threshold for items')\n",
        "parser.add_argument('--split', type=str, default='leave_one_out', help='How to split the datasets')\n",
        "\n",
        "parser.add_argument('--dataset_split_seed', type=int, default=98765)\n",
        "parser.add_argument('--eval_set_size', type=int, default=500,\n",
        "                    help='Size of val and test set when running evaluation')\n",
        "\n",
        "# Dataloader arguments\n",
        "parser.add_argument('--dataloader_random_seed', type=int, default=98765)\n",
        "parser.add_argument('--train_batch_size', type=int, default=64)\n",
        "parser.add_argument('--val_batch_size', type=int, default=64)\n",
        "parser.add_argument('--test_batch_size', type=int, default=64)\n",
        "parser.add_argument('--workers', type=int, default=0)  # Added workers argument\n",
        "\n",
        "# Negative sampler arguments\n",
        "parser.add_argument('--train_negative_sampler_code', type=str, default='random',\n",
        "                    choices=['popular', 'random'], help='Negative sampling technique for training')\n",
        "parser.add_argument('--train_negative_sample_size', type=int, default=0)\n",
        "parser.add_argument('--train_negative_sampling_seed', type=int, default=0)\n",
        "parser.add_argument('--test_negative_sampler_code', type=str, default='random',\n",
        "                    choices=['popular', 'random'], help='Negative sampling technique for evaluation')\n",
        "parser.add_argument('--test_negative_sample_size', type=int, default=100)\n",
        "parser.add_argument('--test_negative_sampling_seed', type=int, default=98765)\n",
        "\n",
        "# Model arguments\n",
        "parser.add_argument('--model_code', type=str, default='bert_genre', choices=['bert', 'dae', 'vae', 'bert_genre'])\n",
        "parser.add_argument('--model_init_seed', type=int, default=0)\n",
        "\n",
        "# BERT arguments\n",
        "parser.add_argument('--bert_max_len', type=int, default=100)\n",
        "parser.add_argument('--bert_num_blocks', type=int, default=2)\n",
        "parser.add_argument('--bert_num_heads', type=int, default=4)\n",
        "parser.add_argument('--bert_hidden_units', type=int, default=256)\n",
        "parser.add_argument('--bert_dropout', type=float, default=0.1)\n",
        "parser.add_argument('--bert_mask_prob', type=float, default=0.15)\n",
        "\n",
        "# Device configuration\n",
        "parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "parser.add_argument('--device_idx', type=str, default='0')\n",
        "parser.add_argument('--num_gpu', type=int, default=1 if torch.cuda.is_available() else 0)\n",
        "\n",
        "# Experiment arguments\n",
        "parser.add_argument('--experiment_dir', type=str, default='experiments')\n",
        "parser.add_argument('--experiment_description', type=str, default='genre_recommendation')\n",
        "\n",
        "# Add template argument\n",
        "parser.add_argument('--template', type=str, default='train_bert_genre')\n",
        "\n",
        "def is_colab_or_ipython():\n",
        "    return any(word in sys.argv[0] for word in ['ipykernel', 'colab', 'kernel'])\n",
        "\n",
        "if is_colab_or_ipython():\n",
        "    # In Colab: Initialize args with default values\n",
        "    args = parser.parse_args([])\n",
        "else:\n",
        "    args = parser.parse_args()\n",
        "    set_template(args)\n",
        "\n",
        "# Set device configuration\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args.device_idx = '0'\n",
        "args.num_gpu = 1 if torch.cuda.is_available() else 0\n",
        "\n",
        "# Apply template settings\n",
        "args = set_template(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBUvYwHXy3qv",
        "outputId": "05b1c9a3-c986-40bd-fdae-fee043c98cc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting options.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Update main.py with genre-specific training function\n",
        "%%writefile main.py\n",
        "# Update main.py\n",
        "import torch\n",
        "from options import args\n",
        "from models import model_factory\n",
        "from dataloaders import dataloader_factory\n",
        "from trainers import trainer_factory\n",
        "import os\n",
        "\n",
        "def train_bert_genre():\n",
        "    \"\"\"Train the BERT genre model with genre-specific metrics\"\"\"\n",
        "    export_root = setup_train(args)\n",
        "    train_loader, val_loader, test_loader = dataloader_factory(args)\n",
        "    model = model_factory(args)\n",
        "    trainer = trainer_factory(args, model, train_loader, val_loader, test_loader, export_root)\n",
        "    trainer.train()\n",
        "\n",
        "def setup_train(args):\n",
        "    \"\"\"Set up training environment\"\"\"\n",
        "    export_root = os.path.join(args.experiment_dir, args.experiment_description)\n",
        "    os.makedirs(export_root, exist_ok=True)\n",
        "    return export_root\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_bert_genre()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5TsSIZg4KLC",
        "outputId": "57a5345c-87cb-46de-d764-f819799a8254"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Update dataloaders/__init__.py\n",
        "%%writefile dataloaders/__init__.py\n",
        "from .base import AbstractDataloader\n",
        "# from .bert import BERTDataloader\n",
        "from .bert_genre import BERTGenreDataloader\n",
        "from datasets import dataset_factory\n",
        "\n",
        "DATALOADERS = {\n",
        "    # 'bert': BERTDataloader,\n",
        "    'bert_genre': BERTGenreDataloader\n",
        "}\n",
        "\n",
        "def dataloader_factory(args):\n",
        "    dataset = dataset_factory(args)\n",
        "    dataloader = DATALOADERS[args.dataloader_code]\n",
        "    dataloader = dataloader(args, dataset)\n",
        "    train, val, test = dataloader.get_pytorch_dataloaders()\n",
        "    return train, val, test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZr-g5WO6-jl",
        "outputId": "30a3a2b7-c41d-4d0b-a018-b79a2f8921e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataloaders/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Update ML1MDataset\n",
        "%%writefile datasets/ml1m_genre.py\n",
        "from .base import AbstractDataset\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class ML1MDataset(AbstractDataset):\n",
        "    @classmethod\n",
        "    def code(cls):\n",
        "        return 'ml-1m'\n",
        "\n",
        "    @classmethod\n",
        "    def url(cls):\n",
        "        return 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "\n",
        "    @classmethod\n",
        "    def zip_file_content_is_folder(cls):\n",
        "        return True\n",
        "\n",
        "    @classmethod\n",
        "    def all_raw_file_names(cls):\n",
        "        return ['ratings.dat', 'movies.dat']\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "        self._load_dataset()\n",
        "        self._set_num_items()\n",
        "        self._split_dataset()\n",
        "\n",
        "    def _load_dataset(self):\n",
        "        df = self.load_ratings_df()\n",
        "        movies_df = self.load_movies_df()\n",
        "\n",
        "        # Create genre mapping\n",
        "        all_genres = set()\n",
        "        for genres in movies_df['genres']:\n",
        "            all_genres.update(genres.split('|'))\n",
        "\n",
        "        self.genre2id = {genre: idx for idx, genre in enumerate(all_genres)}\n",
        "        self.id2genre = {idx: genre for genre, idx in self.genre2id.items()}\n",
        "\n",
        "        # Create movie-genre mapping\n",
        "        self.movie_genre_map = {}\n",
        "        for _, row in movies_df.iterrows():\n",
        "            movie_id = int(row['sid'])\n",
        "            genres = row['genres'].split('|')\n",
        "            self.movie_genre_map[movie_id] = [self.genre2id[genre] for genre in genres]\n",
        "\n",
        "        # Add genre information to dataset\n",
        "        df['genres'] = df['sid'].apply(lambda x: self.movie_genre_map.get(x, []))\n",
        "\n",
        "        self.df = df\n",
        "\n",
        "    def _set_num_items(self):\n",
        "        \"\"\"Set the number of items in the dataset\"\"\"\n",
        "        self._num_items = len(self.movie_genre_map)\n",
        "        print(f\"Number of items: {self._num_items}\")  # Debug print\n",
        "\n",
        "    def _split_dataset(self):\n",
        "        \"\"\"Split the dataset into train, val, and test sets\"\"\"\n",
        "        df = self.df.copy()\n",
        "\n",
        "        # Sort by timestamp\n",
        "        df = df.sort_values('timestamp')\n",
        "\n",
        "        # Group by user\n",
        "        user_groups = df.groupby('uid')\n",
        "\n",
        "        # Split each user's history into train, val, and test\n",
        "        train_data = {}\n",
        "        val_data = {}\n",
        "        test_data = {}\n",
        "\n",
        "        for user_id, group in user_groups:\n",
        "            items = group['sid'].tolist()\n",
        "            if len(items) >= 3:  # Need at least 3 interactions for train/val/test\n",
        "                train_data[user_id] = items[:-2]  # All but last 2 items\n",
        "                val_data[user_id] = items[-2:-1]  # Second to last item\n",
        "                test_data[user_id] = items[-1:]   # Last item\n",
        "            else:\n",
        "                # If user has less than 3 interactions, skip them\n",
        "                continue\n",
        "\n",
        "        self.train = train_data\n",
        "        self.val = val_data\n",
        "        self.test = test_data\n",
        "\n",
        "    def load_ratings_df(self):\n",
        "        folder_path = self._get_rawdata_folder_path()\n",
        "        return pd.read_csv(os.path.join(folder_path, 'ratings.dat'),\n",
        "                          sep='::',\n",
        "                          header=None,\n",
        "                          names=['uid', 'sid', 'rating', 'timestamp'],\n",
        "                          engine='python',\n",
        "                          encoding='ISO-8859-1')\n",
        "\n",
        "    def load_movies_df(self):\n",
        "        folder_path = self._get_rawdata_folder_path()\n",
        "        return pd.read_csv(os.path.join(folder_path, 'movies.dat'),\n",
        "                          sep='::',\n",
        "                          header=None,\n",
        "                          names=['sid', 'title', 'genres'],\n",
        "                          engine='python',\n",
        "                          encoding='ISO-8859-1')\n",
        "\n",
        "    def get_genre_matrix(self, item_ids):\n",
        "        \"\"\"Get genre matrix for given item IDs\"\"\"\n",
        "        genre_matrix = torch.zeros(len(item_ids), len(self.genre2id))\n",
        "        for i, item_id in enumerate(item_ids):\n",
        "            genres = self.movie_genre_map.get(item_id, [])\n",
        "            for genre_id in genres:\n",
        "                genre_matrix[i, genre_id] = 1\n",
        "        return genre_matrix\n",
        "\n",
        "    def get_num_items(self):\n",
        "        return len(self.movie_genre_map)\n",
        "\n",
        "    @property\n",
        "    def num_items(self):\n",
        "        return self.get_num_items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yTVthJI-uS6",
        "outputId": "4d38306a-e9bf-438e-b536-4d9ea8bbb9fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting datasets/ml1m_genre.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update datasets/__init__.py\n",
        "%%writefile datasets/__init__.py\n",
        "from .ml1m_genre import ML1MDataset\n",
        "from .ml_20m import ML20MDataset\n",
        "\n",
        "DATASETS = {\n",
        "    ML1MDataset.code(): ML1MDataset,\n",
        "    ML20MDataset.code(): ML20MDataset\n",
        "}\n",
        "\n",
        "def dataset_factory(args):\n",
        "    dataset = DATASETS[args.dataset_code]\n",
        "    return dataset(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Scyr0_pCoOb",
        "outputId": "8f5c2688-eaca-4b4c-feac-4f77e27cc9b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting datasets/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update models/__init__.py\n",
        "%%writefile models/__init__.py\n",
        "from .bert import BERTModel\n",
        "from .bert_genre import BERTGenreModel\n",
        "\n",
        "MODELS = {\n",
        "    BERTModel.code(): BERTModel,\n",
        "    BERTGenreModel.code(): BERTGenreModel\n",
        "}\n",
        "\n",
        "def model_factory(args):\n",
        "    \"\"\"Factory function to create model based on args\"\"\"\n",
        "    model = MODELS[args.model_code]\n",
        "    return model(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLM0HnfFId5d",
        "outputId": "5970a240-a3e4-43ff-8082-0965af87ba3f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update trainers/__init__.py\n",
        "%%writefile trainers/__init__.py\n",
        "from .bert import BERTTrainer\n",
        "# from .dae import DAERecommenderTrainer\n",
        "# from .vae import VAETrainer\n",
        "from .bert_genre import BERTGenreTrainer  # Import our genre trainer\n",
        "\n",
        "TRAINERS = {\n",
        "    BERTTrainer.code(): BERTTrainer,\n",
        "    # DAERecommenderTrainer.code(): DAERecommenderTrainer,\n",
        "    # VAETrainer.code(): VAETrainer,\n",
        "    BERTGenreTrainer.code(): BERTGenreTrainer  # Add our genre trainer\n",
        "}\n",
        "\n",
        "def trainer_factory(args, model, train_loader, val_loader, test_loader, export_root):\n",
        "    trainer = TRAINERS[args.trainer_code]\n",
        "    return trainer(args, model, train_loader, val_loader, test_loader, export_root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djT2W5qEQV8P",
        "outputId": "f6304ea6-9c50-41ae-8303-88d86a742269"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting trainers/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update BERT genre trainer\n",
        "%%writefile trainers/bert_genre.py\n",
        "from .base import AbstractTrainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "class BERTGenreTrainer(AbstractTrainer):\n",
        "    @classmethod\n",
        "    def code(cls):\n",
        "        return 'bert_genre'\n",
        "\n",
        "    def __init__(self, args, model, train_loader, val_loader, test_loader, export_root):\n",
        "        super().__init__(args, model, train_loader, val_loader, test_loader, export_root)\n",
        "        self.args = args\n",
        "        self.device = args.device\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "        self.best_metric = args.best_metric\n",
        "        self.num_items = args.num_items\n",
        "\n",
        "    def add_extra_loggers(self):\n",
        "        pass\n",
        "\n",
        "    def log_extra_train_info(self, log_data):\n",
        "        pass\n",
        "\n",
        "    def log_extra_val_info(self, log_data):\n",
        "        pass\n",
        "\n",
        "    def calculate_loss(self, batch):\n",
        "        seqs, labels, genre_matrices = batch\n",
        "        seqs = seqs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "        genre_matrices = genre_matrices.to(self.device)\n",
        "\n",
        "        logits = self.model(seqs, genre_matrices)  # [B, G, I]\n",
        "        B, G, I = logits.size()\n",
        "\n",
        "        # Fix shape: from [B, 1, G] ‚Üí [B, G]\n",
        "        if genre_matrices.shape[1] == 1:\n",
        "            genre_matrices = genre_matrices.squeeze(1)\n",
        "\n",
        "        genre_indices = torch.argmax(genre_matrices, dim=1)  # [B]\n",
        "        gather_indices = genre_indices.view(B, 1, 1).expand(-1, 1, I)  # [B, 1, I]\n",
        "        genre_logits = logits.gather(dim=1, index=gather_indices).squeeze(1)  # [B, I]\n",
        "\n",
        "        return self.criterion(genre_logits, labels)\n",
        "\n",
        "    def calculate_metrics(self, batch):\n",
        "        seqs, labels, genre_matrices = batch\n",
        "        seqs = seqs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "        genre_matrices = genre_matrices.to(self.device)\n",
        "\n",
        "        logits = self.model(seqs, genre_matrices)  # [B, G, I]\n",
        "        batch_size, num_genres, num_items = logits.size()\n",
        "\n",
        "        top5 = torch.topk(logits, 5, dim=2).indices  # [B, G, 5]\n",
        "        labels_expanded = labels.unsqueeze(1).expand(-1, num_genres).unsqueeze(2)  # [B, G, 1]\n",
        "        hits = (top5 == labels_expanded).any(dim=2).float()  # [B, G]\n",
        "        recall_per_genre = hits.mean(dim=0)  # [G]\n",
        "\n",
        "        metrics = {f\"Recall@5_Genre{g}\": recall_per_genre[g].item() for g in range(num_genres)}\n",
        "        metrics[\"Recall@5_Avg\"] = recall_per_genre.mean().item()\n",
        "        return metrics\n",
        "\n",
        "    def train_epoch(self, epoch_idx):\n",
        "        self.model.train()\n",
        "        avg_loss = 0.0\n",
        "        for batch_idx, batch in enumerate(tqdm(self.train_loader, desc=f'Epoch {epoch_idx}')):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = self.calculate_loss(batch)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            avg_loss += loss.item()\n",
        "        avg_loss /= (batch_idx + 1)\n",
        "        return {'avg_loss': avg_loss}\n",
        "\n",
        "    def validate_epoch(self, epoch_idx):\n",
        "        self.model.eval()\n",
        "        metrics = {}\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(self.val_loader, desc='Validation'):\n",
        "                batch_metrics = self.calculate_metrics(batch)\n",
        "                for k, v in batch_metrics.items():\n",
        "                    metrics[k] = metrics.get(k, 0) + v\n",
        "        for k in metrics:\n",
        "            metrics[k] /= len(self.val_loader)\n",
        "        return metrics\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        metrics = {}\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(self.test_loader, desc='Testing'):\n",
        "                batch_metrics = self.calculate_metrics(batch)\n",
        "                for k, v in batch_metrics.items():\n",
        "                    metrics[k] = metrics.get(k, 0) + v\n",
        "        for k in metrics:\n",
        "            metrics[k] /= len(self.test_loader)\n",
        "\n",
        "        # Print and save metrics\n",
        "        print(\"\\nüìä Final Evaluation (Test Set):\")\n",
        "        for k, v in metrics.items():\n",
        "            print(f\"{k}: {v:.4f}\")\n",
        "        import json\n",
        "        with open(\"final_recall_metrics.json\", \"w\") as f:\n",
        "            json.dump(metrics, f, indent=2)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def get_genre_recommendations(self):\n",
        "        self.model.eval()\n",
        "        recommendations = {}  # {user_id: {genre: [item_ids]}}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(self.test_loader, desc='Generating Genre-Based Recommendations'):\n",
        "                seqs, labels, genre_matrices = [x.to(self.device) for x in batch]\n",
        "                logits = self.model(seqs, genre_matrices)  # [B, G, I]\n",
        "                top5_items = torch.topk(logits, 5, dim=2).indices  # [B, G, 5]\n",
        "\n",
        "                for i in range(seqs.size(0)):\n",
        "                    user_id = i  # Replace with actual user ID if available\n",
        "                    recommendations[user_id] = {}\n",
        "                    for g in range(logits.size(1)):\n",
        "                        recommendations[user_id][f'Genre_{g}'] = top5_items[i, g].cpu().tolist()\n",
        "\n",
        "        import json\n",
        "        with open('genre_recommendations.json', 'w') as f:\n",
        "            json.dump(recommendations, f, indent=2)\n",
        "        print(\"‚úÖ Genre-based recommendations saved to genre_recommendations.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IEiJIOrRIso",
        "outputId": "1acfe14e-a490-42cd-b9f5-7841de417174"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting trainers/bert_genre.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataloaders import dataloader_factory\n",
        "from models import model_factory\n",
        "from trainers import trainer_factory\n",
        "from options import args\n",
        "import os\n",
        "\n",
        "# Ensure working directory is correct (if not already done)\n",
        "os.chdir('/content/BERT4Rec-VAE-Pytorch')\n",
        "\n",
        "# Set template and required args\n",
        "args.template = 'train_bert_genre'\n",
        "args.metric = \"Recall@5_Avg\"\n",
        "args.best_metric = \"Recall@5_Avg\"\n",
        "args.monitor = \"Recall@5_Avg\"\n",
        "args.num_items = 3953\n",
        "\n",
        "# üõ†Ô∏è Add missing arguments\n",
        "args.result_dir = './results'\n",
        "args.run_name = 'bert_genre_test'\n",
        "\n",
        "# Load data and model\n",
        "train_loader, val_loader, test_loader = dataloader_factory(args)\n",
        "model = model_factory(args).to(args.device)\n",
        "\n",
        "# Create trainer\n",
        "export_root = os.path.join(args.result_dir, args.run_name)\n",
        "trainer = trainer_factory(args, model, train_loader, val_loader, test_loader, export_root)\n"
      ],
      "metadata": {
        "id": "UVsBk4Qusm0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758b31f2-02c9-4213-d40b-30ad6e3c7027"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items: 3883\n",
            "Already preprocessed. Skip preprocessing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "KupTzZ4evVsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a7230009-135c-48fd-8804-f1279624d714"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.22it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update Best Recall@5_Avg Model at 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.69it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 48.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update Best Recall@5_Avg Model at 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2, loss 5.376 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.46it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.40it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.68it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 46.88it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 18.10it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.39it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.10it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 52.88it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 18.38it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 52.82it/s]\n",
            "Epoch 7, loss 0.729 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.24it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.55it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 15.90it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 47.17it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 18.33it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.31it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.04it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 52.50it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 18.19it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.11it/s]\n",
            "Epoch 12, loss 0.201 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.84it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.44it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.82it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.08it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.70it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.56it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.65it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.94it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.89it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.78it/s]\n",
            "Epoch 17, loss 0.141 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.77it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.45it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.72it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.62it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.89it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.45it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.15it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.20it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.99it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.10it/s]\n",
            "Epoch 22, loss 0.114 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.52it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.92it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.76it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 45.58it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.50it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.38it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.90it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.23it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.68it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.40it/s]\n",
            "Epoch 27, loss 0.092 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.79it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.23it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.76it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 47.21it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.19it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.11it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.95it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 48.99it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.54it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.26it/s]\n",
            "Epoch 32, loss 0.100 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.68it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.80it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.87it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 47.48it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.13it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.88it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.17it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 47.35it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.96it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.76it/s]\n",
            "Epoch 37, loss 0.081 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.82it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.37it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.83it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 48.45it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.15it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.70it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.28it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 45.00it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.83it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.51it/s]\n",
            "Epoch 42, loss 0.072 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.70it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.42it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.84it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.50it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.02it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.07it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.40it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 45.11it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.85it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 51.28it/s]\n",
            "Epoch 47, loss 0.067 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.64it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.95it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.82it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.38it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.64it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.56it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.58it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 42.63it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.84it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.13it/s]\n",
            "Epoch 52, loss 0.077 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.62it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.63it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.78it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.83it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.56it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.99it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.70it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.84it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.65it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.72it/s]\n",
            "Epoch 57, loss 0.062 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.67it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.45it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.84it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.77it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.54it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.33it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.85it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.28it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.34it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.25it/s]\n",
            "Epoch 62, loss 0.074 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.99it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.54it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.70it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.92it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.62it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.16it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.87it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 46.37it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.07it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.33it/s]\n",
            "Epoch 67, loss 0.039 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.70it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 47.74it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.74it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.76it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.88it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.00it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.74it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 47.14it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.03it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.52it/s]\n",
            "Epoch 72, loss 0.061 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.06it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 46.64it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.72it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.17it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.80it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.66it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.63it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 48.19it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.99it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.06it/s]\n",
            "Epoch 77, loss 0.065 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.19it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.89it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.74it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.07it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.55it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.55it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.61it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.07it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.70it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.27it/s]\n",
            "Epoch 82, loss 0.048 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.33it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.95it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.55it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.93it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.66it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.67it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.68it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.46it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.64it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.20it/s]\n",
            "Epoch 87, loss 0.046 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.47it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 43.53it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.75it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.17it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.43it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.82it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.74it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.28it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.48it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.00it/s]\n",
            "Epoch 92, loss 0.043 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.40it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.27it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.69it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.77it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.35it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.17it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.73it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 49.80it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.60it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.61it/s]\n",
            "Epoch 97, loss 0.044 : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.60it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:02<00:00, 44.07it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.52it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.43it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 16.63it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 48.57it/s]\n",
            "Logging to Tensorboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:05<00:00, 17.77it/s]\n",
            "Val: N@1 0.000, N@5 0.000, N@10 0.000, R@1 0.000, R@5 0.000, R@10 0.000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 50.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.get_genre_recommendations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alDbjn_nR6Eu",
        "outputId": "8e3df437-844d-4585-e345-9aed09f9515c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Genre-Based Recommendations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:04<00:00, 21.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Genre-based recommendations saved to genre_recommendations.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.test()\n",
        "\n",
        "print(\"üìä Final Evaluation (Test Set):\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKuiCBWZR-fT",
        "outputId": "265322a8-36bd-40ab-fcb1-426b7de582b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 47.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Final Evaluation (Test Set):\n",
            "Recall@5_Genre0: 0.0133\n",
            "Recall@5_Genre1: 0.0086\n",
            "Recall@5_Genre2: 0.0154\n",
            "Recall@5_Genre3: 0.0054\n",
            "Recall@5_Genre4: 0.0018\n",
            "Recall@5_Genre5: 0.0030\n",
            "Recall@5_Genre6: 0.0081\n",
            "Recall@5_Genre7: 0.0033\n",
            "Recall@5_Genre8: 0.0035\n",
            "Recall@5_Genre9: 0.0049\n",
            "Recall@5_Genre10: 0.0036\n",
            "Recall@5_Genre11: 0.0035\n",
            "Recall@5_Genre12: 0.0021\n",
            "Recall@5_Genre13: 0.0023\n",
            "Recall@5_Genre14: 0.0008\n",
            "Recall@5_Genre15: 0.0008\n",
            "Recall@5_Genre16: 0.0016\n",
            "Recall@5_Genre17: 0.0010\n",
            "Recall@5_Avg: 0.0046\n",
            "üìä Final Evaluation (Test Set):\n",
            "Recall@5_Genre0: 0.0133\n",
            "Recall@5_Genre1: 0.0086\n",
            "Recall@5_Genre2: 0.0154\n",
            "Recall@5_Genre3: 0.0054\n",
            "Recall@5_Genre4: 0.0018\n",
            "Recall@5_Genre5: 0.0030\n",
            "Recall@5_Genre6: 0.0081\n",
            "Recall@5_Genre7: 0.0033\n",
            "Recall@5_Genre8: 0.0035\n",
            "Recall@5_Genre9: 0.0049\n",
            "Recall@5_Genre10: 0.0036\n",
            "Recall@5_Genre11: 0.0035\n",
            "Recall@5_Genre12: 0.0021\n",
            "Recall@5_Genre13: 0.0023\n",
            "Recall@5_Genre14: 0.0008\n",
            "Recall@5_Genre15: 0.0008\n",
            "Recall@5_Genre16: 0.0016\n",
            "Recall@5_Genre17: 0.0010\n",
            "Recall@5_Avg: 0.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"genre_recall_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Saved genre recall results to 'genre_recall_results.json'\")\n"
      ],
      "metadata": {
        "id": "xZcXW1KFSDIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define list of modified/created files\n",
        "modified_files = [\n",
        "    \"models/bert_genre.py\",\n",
        "    \"trainers/bert_genre_trainer.py\",\n",
        "    \"dataloaders/bert_genre.py\",\n",
        "    \"templates.py\",\n",
        "    \"options.py\",\n",
        "    \"main.py\",\n",
        "    \"dataloaders/__init__.py\",\n",
        "    \"datasets/ml1m_genre.py\",\n",
        "    \"datasets/__init__.py\",\n",
        "    \"models/__init__.py\",\n",
        "    \"trainers/__init__.py\",\n",
        "    \"trainers/bert_genre.py\",\n",
        "    \"genre_recommendations.json\",               # ‚úÖ Result file 1\n",
        "    \"genre_recall_results.json\",                # ‚úÖ Result file 2\n",
        "    \"final_recall_metrics.json\"\n",
        "    # \"BERT_recommendation_model.ipynb\"  # <-- Your notebook\n",
        "]\n",
        "\n",
        "# Create a directory to store files before zipping\n",
        "os.makedirs(\"BERT4Rec_Submission\", exist_ok=True)\n",
        "\n",
        "# Copy each file to submission folder preserving folder structure\n",
        "for file_path in modified_files:\n",
        "    dest_path = os.path.join(\"BERT4Rec_Submission\", file_path)\n",
        "    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
        "    shutil.copy(file_path, dest_path)\n",
        "\n",
        "# Create the zip archive\n",
        "shutil.make_archive(\"BERT4Rec_Submission\", 'zip', \"BERT4Rec_Submission\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ua3Z3GzMdSeT",
        "outputId": "75fbbfb0-bf5a-446c-a308-238e99fcc9c2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/BERT4Rec-VAE-Pytorch/BERT4Rec_Submission.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"BERT4Rec_Submission.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "x2FEDNwalo-2",
        "outputId": "7abe74ae-f6e1-42c4-c96d-52baa3edee8b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54957471-bf7e-474d-9610-e6f22b4f8856\", \"BERT4Rec_Submission.zip\", 11714)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erg33GQRmLcC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}